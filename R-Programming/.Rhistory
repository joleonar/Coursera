install.packages(reshape2_1.4.1)
install.packages(reshape2)
install.packages("~/Documents/reshape2_1.4.1.tgz")
install.packages("~/Documents/reshape2_1.4.1.tgz", repos = NULL)
library(ggplot2)
library(plyr)
library(ggplot2)
# Import the data
data <- read.csv("out.csv", sep="\t")
data
colnames(data) <- c("time","url")
data$time <- as.POSIXct(data$time)
data$day <- format(data$time, format="%Y-%m-%d")
# Count visits per day
lgrep <- function(x,pat){ c <- grep(pat, x$url); return(length(c)) }
counts.google <- ddply(data, .(day), "lgrep", pat="www.google", .progress="text")
counts.mail <- ddply(data, .(day), "lgrep", pat="mail.google", .progress="text")
counts.facebook <- ddply(data, .(day), "lgrep", pat="facebook", .progress="text")
counts.spiegel <- ddply(data, .(day), "lgrep", pat="spiegel", .progress="text")
counts.nytimes <- ddply(data, .(day), "lgrep", pat="nytimes", .progress="text")
counts.wiki <- ddply(data, .(day), "lgrep", pat="wikipedia", .progress="text")
counts.leo <- ddply(data, .(day), "lgrep", pat="dict.leo", .progress="text")
counts.hulu <- ddply(data, .(day), "lgrep", pat="hulu", .progress="text")
# Make new data.frame
df <- data.frame(day=counts.google$day, Google=counts.google$lgrep, GMail = counts.mail$lgrep, Facebook=counts.facebook$lgrep, SPIEGEL=counts.spiegel$lgrep, NYTimes=counts.nytimes$lgrep, Wikipedia=counts.wiki$lgrep, Leo=counts.leo$lgrep, hulu=counts.hulu$lgrep)
em <- melt(df, id = "day")
# Plot it
ggplot(aes(as.Date(day), value, color = variable), colour=clarity , data=em) +
scale_x_date('') +
stat_smooth() +
scale_y_continuous('visits') +
geom_line(alpha=0.10) +
geom_point(alpha=0.20) +
opts(legend.title = theme_text(colour = 'white', size = 0)) +
scale_colour_brewer(palette="Set1")
em
library(reshape2)
data
data <- read.csv("out.csv", sep="\t")
colnames(data) <- c("time","url")
data$time <- as.POSIXct(data$time)
data$day <- format(data$time, format="%Y-%m-%d")
# Count visits per day
lgrep <- function(x,pat){ c <- grep(pat, x$url); return(length(c)) }
counts.google <- ddply(data, .(day), "lgrep", pat="www.google", .progress="text")
counts.mail <- ddply(data, .(day), "lgrep", pat="mail.google", .progress="text")
counts.facebook <- ddply(data, .(day), "lgrep", pat="facebook", .progress="text")
counts.spiegel <- ddply(data, .(day), "lgrep", pat="spiegel", .progress="text")
counts.nytimes <- ddply(data, .(day), "lgrep", pat="nytimes", .progress="text")
counts.wiki <- ddply(data, .(day), "lgrep", pat="wikipedia", .progress="text")
counts.leo <- ddply(data, .(day), "lgrep", pat="dict.leo", .progress="text")
counts.hulu <- ddply(data, .(day), "lgrep", pat="hulu", .progress="text")
# Make new data.frame
df <- data.frame(day=counts.google$day, Google=counts.google$lgrep, GMail = counts.mail$lgrep, Facebook=counts.facebook$lgrep, SPIEGEL=counts.spiegel$lgrep, NYTimes=counts.nytimes$lgrep, Wikipedia=counts.wiki$lgrep, Leo=counts.leo$lgrep, hulu=counts.hulu$lgrep)
em <- melt(df, id = "day")
# Plot it
ggplot(aes(as.Date(day), value, color = variable), colour=clarity , data=em) +
scale_x_date('') +
stat_smooth() +
scale_y_continuous('visits') +
geom_line(alpha=0.10) +
geom_point(alpha=0.20) +
opts(legend.title = theme_text(colour = 'white', size = 0)) +
scale_colour_brewer(palette="Set1")
# Plot it
ggplot(aes(as.Date(day), value, color = variable), colour=clarity , data=em) +
scale_x_date('') +
stat_smooth() +
scale_y_continuous('visits') +
geom_line(alpha=0.10) +
geom_point(alpha=0.20) +
#opts(legend.title = theme_text(colour = 'white', size = 0)) +
theme(legend.title = theme_text(colour = 'white', size = 0)) +
scale_colour_brewer(palette="Set1")
ggplot(aes(as.Date(day), value, color = variable), colour=clarity , data=em) +
scale_x_date('') +
stat_smooth() +
scale_y_continuous('visits') +
geom_line(alpha=0.10) +
geom_point(alpha=0.20) +
#opts(legend.title = theme_text(colour = 'white', size = 0)) +
#theme(legend.title = theme_text(colour = 'white', size = 0)) +
theme(legend.title = element_text(colour = 'white', size = 0)) +
scale_colour_brewer(palette="Set1")
library(plyr)
library(ggplot2)
library(reshape2)
# Import the data
data <- read.csv("out.csv", sep="\t")
colnames(data) <- c("time","url")
data$time <- as.POSIXct(data$time)
data$day <- format(data$time, format="%Y-%m-%d")
# Count visits per day
lgrep <- function(x,pat){ c <- grep(pat, x$url); return(length(c)) }
counts.google <- ddply(data, .(day), "lgrep", pat="www.google", .progress="text")
counts.r-bloggers <- ddply(data, .(day), "lgrep", pat="r-bloggers", .progress="text")
counts.facebook <- ddply(data, .(day), "lgrep", pat="facebook", .progress="text")
counts.google <- ddply(data, .(day), "lgrep", pat="www.google", .progress="text")
counts.rbloggers <- ddply(data, .(day), "lgrep", pat="r-bloggers", .progress="text")
counts.facebook <- ddply(data, .(day), "lgrep", pat="facebook", .progress="text")
counts.github <- ddply(data, .(day), "lgrep", pat="github", .progress="text")
counts.twitter <- ddply(data, .(day), "lgrep", pat="twitter", .progress="text")
counts.gephi <- ddply(data, .(day), "lgrep", pat="gephi", .progress="text")
counts.data <- ddply(data, .(day), "lgrep", pat="data", .progress="text")
counts.linkedin <- ddply(data, .(day), "lgrep", pat="linkedin", .progress="text")
# Make new data.frame
df <- data.frame(day=counts.google$day,
Google=counts.google$lgrep,
R-Bloggers=counts.r-bloggers$lgrep,
Facebook=counts.facebook$lgrep,
df <- data.frame(day=counts.google$day, Google=counts.google$lgrep, R-Bloggers=counts.r-bloggers$lgrep, Facebook=counts.facebook$lgrep, Github=counts.github$lgrep, Twitter=counts.twitter$lgrep, Gephi=counts.gephi$lgrep, Data=counts.data$lgrep, Linkedin=counts.linkedin$lgrep)
df <- data.frame(day=counts.google$day, Google=counts.google$lgrep, R-Bloggers=counts.rbloggers$lgrep, Facebook=counts.facebook$lgrep, Github=counts.github$lgrep, Twitter=counts.twitter$lgrep, Gephi=counts.gephi$lgrep, Data=counts.data$lgrep, Linkedin=counts.linkedin$lgrep)
df <- data.frame(day=counts.google$day, Google = counts.google$lgrep, R-Bloggers=counts.rbloggers$lgrep, Facebook=counts.facebook$lgrep, Github=counts.github$lgrep, Twitter=counts.twitter$lgrep, Gephi=counts.gephi$lgrep, Data=counts.data$lgrep, Linkedin=counts.linkedin$lgrep)
df <- data.frame(day=counts.google$day, Google = counts.google$lgrep, R-Bloggers = counts.rbloggers$lgrep, Facebook=counts.facebook$lgrep, Github=counts.github$lgrep, Twitter=counts.twitter$lgrep, Gephi=counts.gephi$lgrep, Data=counts.data$lgrep, Linkedin=counts.linkedin$lgrep)
df <- data.frame(day=counts.google$day, Google = counts.google$lgrep, RBloggers = counts.rbloggers$lgrep, Facebook=counts.facebook$lgrep, Github=counts.github$lgrep, Twitter=counts.twitter$lgrep, Gephi=counts.gephi$lgrep, Data=counts.data$lgrep, Linkedin=counts.linkedin$lgrep)
em <- melt(df, id = "day")
# Plot it
ggplot(aes(as.Date(day), value, color = variable), colour=clarity , data=em) +
scale_x_date('') +
stat_smooth() +
scale_y_continuous('visits') +
geom_line(alpha=0.10) +
geom_point(alpha=0.20) +
#opts(legend.title = theme_text(colour = 'white', size = 0)) +
#theme(legend.title = theme_text(colour = 'white', size = 0)) +
theme(legend.title = element_text(colour = 'white', size = 0)) +
scale_colour_brewer(palette="Set1")
registerTwitterOAuth(cred)
load("~/Data Sience/R/twitter authentication.Rdata")
load("~/Data Science/R/twitter authentication.Rdata")
registerTwitterOAuth(cred)
registerTwitterOAuth(cred)
library(twitteR)
registerTwitterOAuth(cred)
mach_tweets = searchTwitter("#datascience")
mach_tweets[1:15]
mach_text = sapply(mach_tweets, function(x) x$getText())
mach_text[1:15]
mach_corpus = Corpus(VectorSource(mach_text))
library(tm)
mach_corpus = Corpus(VectorSource(mach_text))
mach_corpus[1:15]
tdm = TermDocumentMatrix(mach_corpus,
control = list(removePunctuation = TRUE,
stopwords = c("machine", "learning", stopwords("english")),
removeNumbers = TRUE, tolower = TRUE))
m = as.matrix(tdm)
word_freqs = sort(rowSums(m), decreasing=TRUE)
# create a data frame with words and their frequencies
dm = data.frame(word=names(word_freqs), freq=word_freqs)
# plot wordcloud
wordcloud(dm$word, dm$freq, random.order=FALSE, colors=brewer.pal(8, "Dark2"))
library(wordcloud)
library(RColorBrewer)
word_freqs = sort(rowSums(m), decreasing=TRUE)
# create a data frame with words and their frequencies
dm = data.frame(word=names(word_freqs), freq=word_freqs)
# plot wordcloud
wordcloud(dm$word, dm$freq, random.order=FALSE, colors=brewer.pal(8, "Dark2"))
library("reshape2") # melt()
library("ggplot2") # ggplot()
ds <- data.frame(L1=100+c(0, cumsum(runif(99, -20, 20))),
L2=150+c(0, cumsum(runif(99, -10, 10))),
Date=seq.Date(as.Date("2000-01-01"),
by="1 month", length.out=100))
dsm <- melt(ds, id="Date")
g <- ggplot(data=dsm, aes(x=Date, y=value, colour=variable))
g <- g + geom_line()
g <- g + ylab("Observation")
g <- g + labs(colour="Location")
print(g)
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
L2=150+c(0, cumsum(runif(99, -10, 10))),
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
ds
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
ds
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
ds
library(swirl)
install.packages("swirl")
library(swirl)
swirl()
5 + 7
x <- 5 + 7
x
y <- x - 3
y
z <- c(1.1, 9, 3.14)
?c
z
c(z, 555)
c(z, 555, z)
z * 2 + 100
my_sqrt <- z^2 - 1
my_sqrt <- sqrt(z - 1)
my_sqrt
my_div <- z / my_sqrt
my_div
z + c(1,2,3,4) + c(0,10)
c(1,2,3,4) + c(0,10)
c(1, 2, 3, 4) + c(0, 10, 100)
z * 2 + 1000
my_div
getwd()
swirl()
swirl()
5 + 7
x <- 5 + 7
x
y <- x - 3
y
z <- c(1.1, 9, 3.14)
?c
z
c(z, 555, z)
z * 2 + 100
my_sqt <- sqrt(z - 1)
my_sqrt <- sqrt(z - 1)
my_sqrt
my_div <- z / my_sqrt
my_div
c(1, 2, 3, 4) + c(0, 10)
c(1, 2, 3, 4) + c(0, 10, 100)
z * 2 + 1000
my_div
help(swirl)
install_from_swirl("Regression Models")
install_from_swirl("Data Analysis")
install_from_swirl("Mathematical Biostatistics Boot Camp")
install_from_swirl("Open Intro")
install_from_swirl("Getting and Cleaning Data")
install_from_swirl("Statistical Inference")
swirl()
load("~/Data Science/R/twitter_oauth.Rdata")
install.packages("streamR")  # from CRAN
library(streamR)
version()
ver()
install.packages(c("MASS", "Matrix", "NLP", "RColorBrewer", "RCurl", "ROAuth", "RWeka", "RWekajars", "Rcpp", "boot", "cluster", "codetools", "devtools", "digest", "foreign", "httr", "jsonlite", "manipulate", "mgcv", "nlme", "rjson", "rstudioapi", "sp", "tcltk2"))
install.packages(c("MASS", "Matrix", "NLP", "RColorBrewer", "RCurl",
oauth = my_oauth)
x <- c(2,3,5)
class(x)
mode(x)
str(x)
summary(x)
liba
library(swirl)
swirl()
nxt()
cars
mpgCity <- cars$mpgCity
cars$mpgCity
myMPG <- cars$mpgCity
mean(myMPG)
median(myMPG)
table(myMPG)
mode(myMPG)
19
source('~/Data Science/GitHub/Coursera/R-Programming/rankall.R')
rankall("heart attack", 20)
setwd("~/Data Science/GitHub/Coursera/R-Programming")
rankall("heart attack", 20)
source('~/Data Science/GitHub/Coursera/R-Programming/rankall.R')
rankall("heart attack", 20)
source('~/Data Science/GitHub/Coursera/R-Programming/rankall.R')
rankall("heart attack", 20)
rankall("pneumonia", "worst")
source('~/Data Science/GitHub/Coursera/R-Programming/rankall.R')
rankall("pneumonia", "worst")
source('~/.active-rstudio-document')
load(file="fb_oauth")
getFriends(oauth, simplify=F)
save(oauth, file="fb_oauth")
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
Rfacebook
Rfacebook()
str(Rfacebook)
library(Rfacebook)
Rfacebook
Rfacebook()
str(Rfacebook)
Rfacebook()
library(Rfacebook)
load(file="fb_oauth")
getFriends(oauth, simplify=F)
getFriends(oauth, simplify=T)
getFriends(oauth, simplify=F, token=oauth)
getFriends(oauth, simplify=F, token = oauth)
getFriends(oauth, simplify=F, token = fb_oauth)
library(Rfacebook)
oauth <- fbOAuth(app_id = "116673401824088",
app_secret = "887d33716b13422d9f780126701e80e6",
extended_permissions = T)
save(oauth, file="fb_oauth")
getFriends(oauth, simplify=F, token = fb_oauth)
me <- getUsers("me", token=fb_oauth)
library(Rfacebook)
oauth <- fbOAuth(app_id = "116673401824088",
app_secret = "887d33716b13422d9f780126701e80e6",
extended_permissions = T)
save(oauth, file="fb_oauth")
source('~/.active-rstudio-document')
token <- "CAACEdEose0cBAGCtMeDyDrwTD87lxHJXF7ySzWpLX9rzdLIhy6OpyGovCwBj8ODZCW16vHMAAaNVvv9kZCsrRa0QhccajNORRpSbQc1QdZC1lCHI6WxYccCdq3CZBz0jDVMOsleJ6RZA7zpETvy9TcKqTztWi9YTujvzsbtk1MsTFeDHoyeZCwkYXICaZBkv9ZABU574LfcCctPPInZBwyorn"
me <- getUsers("jletteboer", token, private_info = TRUE)
me <- getUsers("jletteboer", token, private_info = TRUE)
me
my_friends <- getFriends(token, simplify = TRUE)
my_friends
my_friends <- getFriends(token, simplify = TRUE)
my_friends <- getFriends(token, simplify = F)
my_friends
my_friends_info <- getUsers(my_friends$id, token, private_info = TRUE)
table(my_friends_info$gender)
source('~/.active-rstudio-document')
save(fb_oauth, file="fb_oauth")
load("fb_oauth")
me <- getUsers("me",token=fb_oauth)
me <- getUsers("jletteboer",token=fb_oauth)
me <- getUsers("jletteboer",token=fb_oauth)
me <- getUsers("me",token=fb_oauth)
my_friends_info <- getUsers(my_friends$id, token, private_info = TRUE)
table(my_friends_info$gender)
fb_oauth <- fbOAuth(app_id="1431236253850974", app_secret="0f0ec57326447aee0e40048dda18dc5a",extended_permissions = TRUE)
set.seed(1)
rnorm(5)
rnorm(5)
rnorm(5)
set.seed(1)
rnorm(5)
system.time()
str(system.time)
system.time()
system.time(readLine("http://www.networkx.nl"))
system.time(readLines("http://www.networkx.nl"))
system.time(readLines("http://www.networkx.nl"))
system.time(readLines("http://www.google.nl"))
system.time(readLines("http://www.networkx.nl"))
?Rprof
set.seed(1)
rpois(5, 2)
rpois(5, 2)
rpois(5, 2)
rpois(5, 2)
rpois(5, 2)
rpois(5, 2)
set.seed(2)
rpois(5, 2)
rpois(5, 2)
rpois(5, 2)
rpois(5, 2)
rpois(5, 2)
rpois(5, 2)
rpois(5, 2)
set.seed(1)
rpois(5, 2)
rpois(5, 2)
rpois(5, 2)
set.seed(1)
rpois(5, 2)
?set.seed
set.seed(10)
x <- rep(0:1, each = 5)
e <- rnorm(10, 0, 20)
y <- 0.5 + 2 * x + e
y
data <- read.csv("outcome-of-care-measures.csv", colClasses = "character")
View(data)
unique(data$State)
source('~/Data Science/GitHub/Coursera/R-Programming/rankall.R')
rankall("heart attack", 20)
unique(data$State)
order(unique(data$State)
)
uniq_states <- unique(data$State)
uniq_states[order(states)]
uniq_states[order(state)]
uniq_states[order(uniq_states)]
source('~/Data Science/GitHub/Coursera/R-Programming/rankall.R')
rankall("heart attack", 20)
sub <- subset(data, select = c(Hospital.Name, State, Hospital.30.Day.Death..Mortality..Rates.from.Heart.Attack))
View(sub)
colnames(sub) <- c("hospital", "state", "rate")
View(sub)
uniq_states <- unique(sub$state)
uniq_states <- uniq_states[order(uniq_states)]
sub[,3] <- as.numeric(sub[,3])
View(sub)
sub[index[1], ]
index <- with(sub, order(rate, hospital, na.last=NA))
sub[index[1], ]
sub[index[20], ]
data_by_state <- split(full_data[, c("Hospital.Name", "State", column)], full_data$State)
data_by_state <- split(data[, c("Hospital.Name", "State", column)], data$State)
data_by_state <- split(data[, c("Hospital.Name", "State", 11)], data$State)
data_by_state <- split(data[, c("Hospital.Name", "State", data[11])], data$State)
data_by_state <- split(data[, c("Hospital.Name", "State", data[, 11])], data$State)
column <- full_data[, 11] <- as.numeric(full_data[, 11])
column <- data[, 11] <- as.numeric(data[, 11])
data_by_state <- split(data[, c("Hospital.Name", "State", column)], data$State)
data_by_state <- split(data[, c("Hospital.Name", "State", column)], data$State)
column
full_data <- read.csv("outcome-of-care-measures.csv", colClasses="character")
column <- full_data[, 11] <- as.numeric(full_data[, 11])
data_by_state <- split(full_data[, c("Hospital.Name", "State", column)], full_data$State)
data_by_state <- split(full_data[, c("Hospital.Name", "State", "Hospital.30.Day.Death..Mortality..Rates.from.Heart.Attack")], full_data$State)
data_by_state
source('~/Data Science/GitHub/Coursera/R-Programming/rankall.R')
rankall("heart attack", 20)
source('~/Data Science/GitHub/Coursera/R-Programming/rankall.R')
rankall("heart attack", 20)
data <- read.csv("outcome-of-care-measures.csv", colClasses = "character")
sub <- split(data[, c("Hospital.Name", "State", "Hospital.30.Day.Death..Mortality..Rates.from.Heart.Attack")], data$State)
source('~/Data Science/GitHub/Coursera/R-Programming/rankall.R')
rankall("heart attack", 20)
source('~/Data Science/GitHub/Coursera/R-Programming/rankall.R')
rankall("heart attack", 20)
sub
colnames(sub)
str(sub)
head(str(sub))
head(str(sub), 5)
head(str(sub), 1)
head(str(sub))
names(sub)
names(sub)[1]
names(sub$1
names(sub$1)
names(sub$[1])
names(sub[1])
names(sub[-1])
rownames(sub)
sub
sub$AK
class(sub)
str(sub)
name.State <- c("state")
names(sub)
remove(name.State)
sub[3]
source('~/Data Science/GitHub/Coursera/R-Programming/rankall.R')
rankall("heart attack", 20)
traceback
rankall("heart attack", 20)
traceback()
index <- with(sub, order(sub[3], sub[1], na.last=NA))
index
data <- read.csv("outcome-of-care-measures.csv", colClasses = "character")
data[,11][,17][,23] <- as.numeric(data[,11][,17][,23])
source('~/Data Science/GitHub/Coursera/R-Programming/rankall.R')
rankall("heart attack", 20)
source('~/Data Science/GitHub/Coursera/R-Programming/rankall.R')
rankall("heart attack", 20)
source('~/Data Science/GitHub/Coursera/R-Programming/rankall.R')
rankall("heart attack", 20)
source('~/Data Science/GitHub/Coursera/R-Programming/rankall.R')
rankall("heart attack", 20)
source('~/Data Science/GitHub/Coursera/R-Programming/rankall.R')
rankall("heart attack", 20)
head(rankall("heart attack", 20), 10)
tail(rankall("pneumonia", "worst"), 3)
tail(rankall("heart failure"), 10)
source('~/Data Science/GitHub/Coursera/R-Programming/rankall.R')
tail(rankall("heart failure"), 10)
data <- read.csv("outcome-of-care-measures.csv", colClasses = "character")
for (i in c(11,17,23)) {
data[,i] <- as.numeric(data[,i])
}
View(data)
source('~/Data Science/GitHub/Coursera/R-Programming/rankall.R')
head(rankall("heart attack", 20), 10)
head(rankall("heart attack", 2000), 10)
head(rankall("heart attack", 20), 10)
tail(rankall("heart failure"), 10)
tail(rankall("pneumonia", "worst"), 3)
source("http://d396qusza40orc.cloudfront.net/rprog%2Fscripts%2Fsubmitscript3.R")
submit()
submit()
submit()
library("swirl")
swirl()
5 + 7
x <- 5 + 7
x
y <- x - 3
y
z <- c(1.1, 9, 3.14)
?c
z
c(z, 555, z)
z * 2 + 100
my_sqrt <- sqrt(z - 1)
my_sqrt
my_div <- z / my_sqrt
my_div
c(1, 2, 3, 4) + c(0, 10)
c(1, 2, 3, 4) + c(0, 10, 100)
z * 2 + 1000
my_div
